#!/bin/bash
# Qwen2.5-7B AliMeeting4MUG LoRA å¾®è°ƒç¯å¢ƒé…ç½®è„šæœ¬
# ç”¨æ³•: bash setup.sh

set -e

echo "========================================"
echo "Qwen2.5-7B AliMeeting4MUG å¾®è°ƒç¯å¢ƒé…ç½®"
echo "========================================"

# æ£€æŸ¥ conda æ˜¯å¦å¯ç”¨
if ! command -v conda &> /dev/null; then
    echo "âŒ æœªæ‰¾åˆ° condaï¼Œè¯·å…ˆå®‰è£… Miniconda æˆ– Anaconda"
    echo "   ä¸‹è½½åœ°å€: https://docs.conda.io/en/latest/miniconda.html"
    exit 1
fi

# ç¯å¢ƒåç§°
ENV_NAME="qwen_finetune"

# æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å·²å­˜åœ¨
if conda env list | grep -q "^${ENV_NAME} "; then
    echo "âš ï¸  ç¯å¢ƒ ${ENV_NAME} å·²å­˜åœ¨"
    read -p "æ˜¯å¦åˆ é™¤å¹¶é‡æ–°åˆ›å»º? (y/n) " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        conda env remove -n ${ENV_NAME} -y
    else
        echo "ä½¿ç”¨ç°æœ‰ç¯å¢ƒ..."
        source $(conda info --base)/etc/profile.d/conda.sh
        conda activate ${ENV_NAME}
    fi
fi

# åˆ›å»º conda ç¯å¢ƒ
if ! conda env list | grep -q "^${ENV_NAME} "; then
    echo "ğŸ“¦ åˆ›å»º Conda ç¯å¢ƒ: ${ENV_NAME}"
    conda create -n ${ENV_NAME} python=3.10 -y
fi

# æ¿€æ´»ç¯å¢ƒ
source $(conda info --base)/etc/profile.d/conda.sh
conda activate ${ENV_NAME}

echo "âœ… ç¯å¢ƒå·²æ¿€æ´»: ${ENV_NAME}"

# æ£€æµ‹ CUDA ç‰ˆæœ¬
echo "ğŸ” æ£€æµ‹ CUDA ç‰ˆæœ¬..."
if command -v nvcc &> /dev/null; then
    CUDA_VERSION=$(nvcc --version | grep "release" | sed 's/.*release \([0-9]*\.[0-9]*\).*/\1/')
    echo "   æ£€æµ‹åˆ° CUDA: ${CUDA_VERSION}"
else
    echo "   æœªæ£€æµ‹åˆ° nvccï¼Œä½¿ç”¨é»˜è®¤ CUDA 11.8"
    CUDA_VERSION="11.8"
fi

# å®‰è£… PyTorch
echo "ğŸ“¦ å®‰è£… PyTorch..."
if [[ "$CUDA_VERSION" == "12."* ]]; then
    pip install torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
else
    pip install torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
fi

# å®‰è£…é¡¹ç›®ä¾èµ–
echo "ğŸ“¦ å®‰è£…é¡¹ç›®ä¾èµ–..."
pip install -r requirements.txt

# å…‹éš† LLaMA-Factory (å¦‚æœä¸å­˜åœ¨)
if [ ! -d "LLaMA-Factory" ]; then
    echo "ğŸ“¦ å…‹éš† LLaMA-Factory..."
    git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
fi

# å®‰è£… LLaMA-Factory
echo "ğŸ“¦ å®‰è£… LLaMA-Factory..."
cd LLaMA-Factory
pip install -e ".[torch,metrics]"
cd ..

# å°è¯•å®‰è£… Flash Attention (å¯èƒ½å¤±è´¥)
echo "ğŸ“¦ å°è¯•å®‰è£… Flash Attention 2 (å¯é€‰)..."
pip install flash-attn --no-build-isolation 2>/dev/null || echo "âš ï¸  Flash Attention å®‰è£…å¤±è´¥ï¼Œè·³è¿‡"

# éªŒè¯å®‰è£…
echo ""
echo "========================================"
echo "éªŒè¯å®‰è£…"
echo "========================================"
python -c "import torch; print(f'âœ… PyTorch: {torch.__version__}')"
python -c "import torch; print(f'âœ… CUDA å¯ç”¨: {torch.cuda.is_available()}')"
python -c "import torch; print(f'âœ… GPU æ•°é‡: {torch.cuda.device_count()}')" 2>/dev/null || true
llamafactory-cli version

echo ""
echo "========================================"
echo "âœ… ç¯å¢ƒé…ç½®å®Œæˆ!"
echo "========================================"
echo ""
echo "ä¸‹ä¸€æ­¥æ“ä½œ:"
echo "  1. æ¿€æ´»ç¯å¢ƒ: conda activate ${ENV_NAME}"
echo "  2. ä¸‹è½½æ¨¡å‹: python scripts/download_model.py"
echo "  3. é¢„å¤„ç†æ•°æ®: python scripts/preprocess_data.py"
echo "  4. å¼€å§‹è®­ç»ƒ: llamafactory-cli train configs/train_lora.yaml"
echo ""
