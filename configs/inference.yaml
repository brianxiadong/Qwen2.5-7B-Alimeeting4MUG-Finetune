### Model Configuration
model_name_or_path: /data/Alimeeting4MUG/models/Qwen/Qwen2.5-7B
trust_remote_code: true

### Adapter Configuration
adapter_name_or_path: ./outputs/qwen2.5-7b-mug-lora
finetuning_type: lora

### Quantization (disabled for bf16 trained model)
# quantization_bit: 4
# quantization_method: bitsandbytes

### Inference Configuration
template: qwen
infer_backend: huggingface

### Generation Parameters
do_sample: false
num_beams: 4
max_new_tokens: 32
repetition_penalty: 1.5
